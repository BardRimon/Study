{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EXAtPGCSVzE",
        "outputId": "ed8d231c-50cb-421e-f450-8cf428eec8ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[ИМЯ] Геннадьевна,\n",
            "\n",
            "Как шеф-повар, я должен выразить свою обеспокоенность слухами о появлении плесени вблизи некоторых кухонь в корпусе 13 по адресу: [ИМЯ], 42. Обращаю ваше внимание на то, что любые продукты, обрабатываемые, приготавливаемые или потребляемые вблизи плесени, могут быть заражены и небезопасны для употребления.\n",
            "\n",
            "Если эти сообщения найдут подтверждения, мне придется закрыть несколько столовых. Возможно распределение нагрузки на кухни в корпусах:\n",
            "№9[АДРЕС]\n",
            "№10[АДРЕС]\n",
            "№11[АДРЕС]\n",
            "\n",
            "С уважением,\n",
            "[ИМЯ].\n",
            "[EMAIL]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1\n",
        "import re\n",
        "\n",
        "email = \"\"\"\n",
        "Уважаемая Эльвира Геннадьевна,\n",
        "\n",
        "Как шеф-повар, я должен выразить свою обеспокоенность слухами о появлении плесени вблизи некоторых кухонь в корпусе 13 по адресу: Льва Толстого, 42. Обращаю ваше внимание на то, что любые продукты, обрабатываемые, приготавливаемые или потребляемые вблизи плесени, могут быть заражены и небезопасны для употребления.\n",
        "\n",
        "Если эти сообщения найдут подтверждения, мне придется закрыть несколько столовых. Возможно распределение нагрузки на кухни в корпусах:\n",
        "№9 площадь Гагарина, 99\n",
        "№10 улица Южная, 10\n",
        "№11 Кривой проспект, 17\n",
        "\n",
        "С уважением,\n",
        "Алексей Мартынов.\n",
        "martyn@supercorp.ru\n",
        "\"\"\"\n",
        "\n",
        "# Маскировка имен (ФИО)\n",
        "email = re.sub(r'([А-ЯЁ][а-яё]+[\\s-][А-ЯЁ][а-яё]+(?:ович|евич|овна|евна)?)', '[ИМЯ]', email)\n",
        "\n",
        "# Маскировка адресов\n",
        "email = re.sub(r'([А-Яа-яёЁ\\s-]+,\\s*\\d+)', '[АДРЕС]', email)\n",
        "\n",
        "# Маскировка email\n",
        "email = re.sub(r'[\\w\\.-]+@[\\w\\.-]+', '[EMAIL]', email)\n",
        "\n",
        "print(email)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/resrekpsxk3yd4d/vacancies.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p4oxXPlUByi",
        "outputId": "224bbca6-dc7a-437c-e9d7-88d2ed3b6a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-07 15:14:51--  https://www.dropbox.com/s/resrekpsxk3yd4d/vacancies.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:601c:18::a27d:612\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.dropbox.com/scl/fi/arvkzclltciuf39v5w8ke/vacancies.csv?rlkey=cmdn4394g12a5vdjwjpuimmbw [following]\n",
            "--2025-05-07 15:14:51--  https://www.dropbox.com/scl/fi/arvkzclltciuf39v5w8ke/vacancies.csv?rlkey=cmdn4394g12a5vdjwjpuimmbw\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc589e8ce09197dfad9a6c1c94f8.dl.dropboxusercontent.com/cd/0/inline/CpNnfXemvvsJnwoNkzMJKJC3rW8C4gUPJnJS-BUlnTB3pV5T-nBctrfFNsM3_NSxa1epDzCl9qfKVS79OWNdQce1njafEt8s3imXYtTYAKBr9Dcyt5IDphsZE2TOFSV8e96pN0VymLBx4M3upA6sz5zB/file# [following]\n",
            "--2025-05-07 15:14:51--  https://uc589e8ce09197dfad9a6c1c94f8.dl.dropboxusercontent.com/cd/0/inline/CpNnfXemvvsJnwoNkzMJKJC3rW8C4gUPJnJS-BUlnTB3pV5T-nBctrfFNsM3_NSxa1epDzCl9qfKVS79OWNdQce1njafEt8s3imXYtTYAKBr9Dcyt5IDphsZE2TOFSV8e96pN0VymLBx4M3upA6sz5zB/file\n",
            "Resolving uc589e8ce09197dfad9a6c1c94f8.dl.dropboxusercontent.com (uc589e8ce09197dfad9a6c1c94f8.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:601c:15::a27d:60f\n",
            "Connecting to uc589e8ce09197dfad9a6c1c94f8.dl.dropboxusercontent.com (uc589e8ce09197dfad9a6c1c94f8.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4692392 (4.5M) [text/plain]\n",
            "Saving to: ‘vacancies.csv.1’\n",
            "\n",
            "vacancies.csv.1     100%[===================>]   4.47M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-05-07 15:14:52 (154 MB/s) - ‘vacancies.csv.1’ saved [4692392/4692392]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "\n",
        "data = pd.read_csv('vacancies.csv')\n",
        "java_vacancies.columns.tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMgHfhVkUQF7",
        "outputId": "b04bf7a1-55c9-4937-b426-5a8e79ca565a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['id', 'name', 'city', 'employer', 'publication_date', 'description']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Фильтрация Java-вакансий\n",
        "java_vacancies = data[data['name'].str.contains('java|Java|JAVA', case=False, regex=True)]\n",
        "\n",
        "# Сбор всех навыков\n",
        "all_skills = []\n",
        "for desc in java_vacancies['description']:\n",
        "    if isinstance(desc, str):\n",
        "        skills = [skill.strip().lower() for skill in desc.split(',')]\n",
        "        all_skills.extend(skills)\n",
        "\n",
        "# Подсчет и вывод топ-5\n",
        "skill_counts = Counter(all_skills)\n",
        "top_skills = skill_counts.most_common(5)\n",
        "print(\"Топ-5 навыков для Java-разработчика:\")\n",
        "for skill, count in top_skills:\n",
        "    print(f\"{skill}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBjRpVVyTve6",
        "outputId": "6e5f3f7a-8a31-4bd5-a3bc-c781d99b89bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Топ-5 навыков для Java-разработчика:\n",
            "hibernate: 26\n",
            "git: 22\n",
            "jms: 19\n",
            "spring: 19\n",
            "конференции: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn_crfsuite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1yjUvJZUweN",
        "outputId": "77883967-470a-4acf-a155-26634977c879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklearn_crfsuite\n",
            "  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting python-crfsuite>=0.9.7 (from sklearn_crfsuite)\n",
            "  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from sklearn_crfsuite) (1.6.1)\n",
            "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from sklearn_crfsuite) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.11/dist-packages (from sklearn_crfsuite) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->sklearn_crfsuite) (3.6.0)\n",
            "Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-crfsuite, sklearn_crfsuite\n",
            "Successfully installed python-crfsuite-0.9.11 sklearn_crfsuite-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://www.dropbox.com/s/iuwsx5pmfhkk0w2/ner_dataset.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4yQKezzVo_M",
        "outputId": "08115759-6035-4f87-e20d-76281dbcab8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-07 15:21:44--  https://www.dropbox.com/s/iuwsx5pmfhkk0w2/ner_dataset.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:601c:18::a27d:612\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.dropbox.com/scl/fi/cu61u8g7z5thol0npjj7f/ner_dataset.csv?rlkey=rb70mhtw6yu4r4bu49qoxbjj4 [following]\n",
            "--2025-05-07 15:21:45--  https://www.dropbox.com/scl/fi/cu61u8g7z5thol0npjj7f/ner_dataset.csv?rlkey=rb70mhtw6yu4r4bu49qoxbjj4\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc9ea0938de46ce6cdaf5ca53305.dl.dropboxusercontent.com/cd/0/inline/CpNDmk6vd0KJNPbVrSXXmoHpzXLSiM6cpRmXWKLqX9GZLqmqwgScUEfsl1PxBLkAa2u7xYW6srhgwN9Kr9k1WEld7aTmqirXfYhp3lb9z3k9wuJRWceTmw4UiwnL5KYmNzUriG2-vhR9XAQDVOEwI3jT/file# [following]\n",
            "--2025-05-07 15:21:45--  https://uc9ea0938de46ce6cdaf5ca53305.dl.dropboxusercontent.com/cd/0/inline/CpNDmk6vd0KJNPbVrSXXmoHpzXLSiM6cpRmXWKLqX9GZLqmqwgScUEfsl1PxBLkAa2u7xYW6srhgwN9Kr9k1WEld7aTmqirXfYhp3lb9z3k9wuJRWceTmw4UiwnL5KYmNzUriG2-vhR9XAQDVOEwI3jT/file\n",
            "Resolving uc9ea0938de46ce6cdaf5ca53305.dl.dropboxusercontent.com (uc9ea0938de46ce6cdaf5ca53305.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:601c:15::a27d:60f\n",
            "Connecting to uc9ea0938de46ce6cdaf5ca53305.dl.dropboxusercontent.com (uc9ea0938de46ce6cdaf5ca53305.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15208151 (15M) [text/plain]\n",
            "Saving to: ‘ner_dataset.csv’\n",
            "\n",
            "ner_dataset.csv     100%[===================>]  14.50M  48.4MB/s    in 0.3s    \n",
            "\n",
            "2025-05-07 15:21:46 (48.4 MB/s) - ‘ner_dataset.csv’ saved [15208151/15208151]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\")\n",
        "data = data.fillna(method=\"ffill\")\n",
        "\n",
        "agg_func = lambda s: [[w, p, t] for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                   s[\"POS\"].values.tolist(),\n",
        "                                                   s[\"Tag\"].values.tolist())]\n",
        "grouped = data.groupby(\"Sentence #\").apply(agg_func).values.tolist()\n",
        "\n",
        "X_list = [[word[:2] for word in sentence] for sentence in grouped]\n",
        "y_list = [[word[2] for word in sentence] for sentence in grouped]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGdqS9jsWALw",
        "outputId": "9c588a22-1057-49ed-e03c-79e60d232586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-1b9e290aec29>:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  data = data.fillna(method=\"ffill\")\n",
            "<ipython-input-17-1b9e290aec29>:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  grouped = data.groupby(\"Sentence #\").apply(agg_func).values.tolist()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_test, y_train, y_test = train_test_split(X_list, y_list, test_size=0.2, random_state=1337)"
      ],
      "metadata": {
        "id": "zCuRw0EGWAOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "\n",
        "    features = {\n",
        "        'word.lower()': word.lower(),\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'postag': postag,\n",
        "        ### Your code goes here ###\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "            ### Your code goes here ###\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][1]\n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "            ### Your code goes here ###\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]"
      ],
      "metadata": {
        "id": "6vTnL8NdWDji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [sent2features(s) for s in data_train]\n",
        "X_test = [sent2features(s) for s in data_test]"
      ],
      "metadata": {
        "id": "tG6_kyooWH-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3\n",
        "\n",
        "from sklearn_crfsuite import CRF\n",
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "\n",
        "# Добавление новых признаков в word2features\n",
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "\n",
        "    features = {\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:],\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'postag': postag,\n",
        "        'postag[:2]': postag[:2],\n",
        "    }\n",
        "\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "            '-1:postag': postag1,\n",
        "            '-1:postag[:2]': postag1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][1]\n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "            '+1:postag': postag1,\n",
        "            '+1:postag[:2]': postag1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "# Остальной код остается как в baseline\n",
        "crf = CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
        "crf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = crf.predict(X_test)\n",
        "print(flat_classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzTmEFd-Tvh7",
        "outputId": "a94e8a92-5140-4d9c-a568-a333e246d713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-art       0.41      0.11      0.18        62\n",
            "       B-eve       0.64      0.52      0.57        48\n",
            "       B-geo       0.86      0.91      0.89      7591\n",
            "       B-gpe       0.97      0.93      0.95      3211\n",
            "       B-nat       0.48      0.31      0.38        35\n",
            "       B-org       0.80      0.75      0.78      4018\n",
            "       B-per       0.86      0.83      0.85      3362\n",
            "       B-tim       0.93      0.88      0.90      4086\n",
            "       I-art       0.46      0.10      0.17        58\n",
            "       I-eve       0.33      0.26      0.29        27\n",
            "       I-geo       0.83      0.79      0.81      1572\n",
            "       I-gpe       0.90      0.58      0.70        45\n",
            "       I-nat       0.40      0.33      0.36         6\n",
            "       I-org       0.82      0.82      0.82      3372\n",
            "       I-per       0.86      0.91      0.89      3432\n",
            "       I-tim       0.86      0.75      0.80      1354\n",
            "           O       0.99      0.99      0.99    177713\n",
            "\n",
            "    accuracy                           0.97    209992\n",
            "   macro avg       0.73      0.63      0.67    209992\n",
            "weighted avg       0.97      0.97      0.97    209992\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-contrib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOU6-pm3XDIW",
        "outputId": "b1f1c81f-3fe0-4009-cc17-9f79d820acdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement keras-contrib (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for keras-contrib\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hVge2Z8wXjm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Подготовка данных\n",
        "words = list(set(data[\"Word\"].values))\n",
        "words.append(\"ENDPAD\")\n",
        "n_words = len(words)ф\n",
        "word2idx = {w: i for i, w in enumerate(words)}\n",
        "\n",
        "# Подготовка тегов\n",
        "tags = list(set(data[\"Tag\"].values))\n",
        "n_tags = len(tags)\n",
        "tag2idx = {t: i for i, t in enumerate(tags)}\n",
        "\n",
        "# Преобразование предложений в индексы\n",
        "max_len = 50\n",
        "X = [[word2idx[w[0]] for w in s] for s in grouped]\n",
        "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=n_words-1)\n",
        "\n",
        "# Преобразование тегов в индексы и one-hot encoding\n",
        "y = [[tag2idx[w[2]] for w in s] for s in grouped]\n",
        "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])  # \"O\" - тег для padding\n",
        "y = [to_categorical(i, num_classes=n_tags) for i in y]  # One-hot encoding\n",
        "\n",
        "# Разделение на train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Создание модели\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=n_words,\n",
        "                   output_dim=50,\n",
        "                   input_length=max_len,\n",
        "                   trainable=True))\n",
        "model.add(Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1)))\n",
        "model.add(TimeDistributed(Dense(n_tags, activation=\"softmax\")))\n",
        "\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Обучение модели\n",
        "history = model.fit(\n",
        "    np.array(X_train),\n",
        "    np.array(y_train),\n",
        "    batch_size=32,\n",
        "    epochs=5,\n",
        "    validation_split=0.1,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZWvYzN1TvlF",
        "outputId": "d2b6e66a-b888-4962-827d-11c7465e435a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 213ms/step - accuracy: 0.9399 - loss: 0.3172 - val_accuracy: 0.9808 - val_loss: 0.0652\n",
            "Epoch 2/5\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 211ms/step - accuracy: 0.9847 - loss: 0.0521 - val_accuracy: 0.9840 - val_loss: 0.0533\n",
            "Epoch 3/5\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 210ms/step - accuracy: 0.9892 - loss: 0.0357 - val_accuracy: 0.9854 - val_loss: 0.0485\n",
            "Epoch 4/5\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 214ms/step - accuracy: 0.9911 - loss: 0.0281 - val_accuracy: 0.9853 - val_loss: 0.0480\n",
            "Epoch 5/5\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 224ms/step - accuracy: 0.9922 - loss: 0.0242 - val_accuracy: 0.9851 - val_loss: 0.0506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2eBeXBs8c9Bp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}