{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdMmEVePskeIpSPZOHX1qy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BardRimon/Study/blob/main/Introduction_in_NLP/%D0%97%D0%B0%D0%B4%D0%B0%D0%BD%D0%B8%D0%B5_4_%D0%90%D0%BB%D0%B5%D0%BA%D1%81%D0%B0%D0%BD%D0%B4%D1%80_%D0%9A%D0%BB%D1%8E%D0%BA%D0%B8%D0%BD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тема 4. Морфологический анализ\n",
        "\n",
        "\n",
        "1. Маскировать все имена собственные в электронном письме.\n",
        "2. Заменить с помощью pymorphy выбранный объект в статье википедии на другой объект (со склонением).\n",
        "3. Запустить два разных морфологических анализатора на одном тексте, привести три токена, для которых автоматически определились разные леммы; расшифровать предсказанные для них морфологические теги.\n",
        "4. Визуализировать на двумерном графике 100 word2vec-токенов (нужно указывать часть речи) из новостных текстов с помощью алгоритма t-SNE.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0dMGXeOxN8VL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TyDPRO6nHtiq",
        "outputId": "f00a028d-ff33-4bc0-9b52-343232d32aba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymystem3 in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pymystem3) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pymystem3) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pymystem3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pymystem3) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pymystem3) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "! pip install pymystem3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "email = \"\"\"\n",
        "Уважаемая Эльвира Геннадьевна,\n",
        "\n",
        "Как шеф-повар, я должен выразить свою обеспокоенность слухами о появлении плесени вблизи некоторых кухонь в корпусе 13 по адресу: Льва Толстого, 42. Обращаю ваше внимание на то, что любые продукты, обрабатываемые, приготавливаемые или потребляемые вблизи плесени, могут быть заражены и небезопасны для употребления.\n",
        "\n",
        "Если эти сообщения найдут подтверждения, мне придется закрыть несколько столовых. Возможно распределение нагрузки на кухни в корпусах:\n",
        "№9 площадь Гагарина, 99\n",
        "№10 улица Южная, 10\n",
        "\n",
        "С уважением,\n",
        "Алексей Мартынов.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_wCDgvGfOYtM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymystem3\n",
        "import re\n",
        "\n",
        "def  name_mask(text):\n",
        "\n",
        "    mystem = pymystem3.Mystem()\n",
        "    masked_text = ''\n",
        "    analyzed = mystem.analyze(text)\n",
        "    for word in analyzed:\n",
        "        if 'analysis' in word and word['analysis']:\n",
        "            gr = word['analysis'][0]['gr']\n",
        "            if 'имя' in gr or 'фам' in gr or 'отч' in gr or 'гео' in gr:\n",
        "                masked_text += '***'\n",
        "            else:\n",
        "                masked_text += word['text']\n",
        "        else:\n",
        "            masked_text += word['text']\n",
        "    return masked_text\n",
        "print(name_mask(email))"
      ],
      "metadata": {
        "id": "MbhBLLxoO0oI",
        "outputId": "a838565d-0550-4b2a-a655-6395ed025e1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Уважаемая *** ***,\n",
            "\n",
            "Как шеф-повар, я должен выразить свою обеспокоенность слухами о появлении плесени вблизи некоторых кухонь в корпусе 13 по адресу: *** ***, 42. Обращаю ваше внимание на то, что любые продукты, обрабатываемые, приготавливаемые или потребляемые вблизи плесени, могут быть заражены и небезопасны для употребления.\n",
            "\n",
            "Если эти сообщения найдут подтверждения, мне придется закрыть несколько столовых. Возможно распределение нагрузки на кухни в корпусах:\n",
            "№9 площадь ***, 99\n",
            "№10 улица Южная, 10\n",
            "\n",
            "С уважением,\n",
            "*** ***.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далее придётся использовать pymorphy"
      ],
      "metadata": {
        "id": "Pe7gyTahQvwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример входных данных (взято по ссылке из гугл диска)\n",
        "orig_wikitext = \"\"\"Стрекозы (лат. Odonáta) — отряд древних летающих насекомых, насчитывающий в мировой фауне свыше 6650 видов. Это относительно крупные насекомые, с подвижной головой, большими глазами, короткими щетинковидными усиками, удлинённым стройным брюшком и четырьмя прозрачными крыльями с густой сетью жилок. Стрекозы — активные специализированные хищники, которые питаются насекомыми, пойманными на лету. Представители отряда широко распространены по миру, встречаясь на всех материках, исключая Антарктиду.\n",
        "Все представители отряда ведут амфибионтный образ жизни — яйца и личинки развиваются в водной среде, а имаго (взрослые) обитают на суше, освоив воздушную среду и став прекрасными летунами. Взрослые стрекозы не ограничиваются в выборе места обитания одними только берегами водоёмов и могут улетать от них на значительные расстояния, встречаясь на лугах, опушках лесов и даже в населённых пунктах. Развитие с неполным превращением: имеются стадии яйца, личинки и имаго. Личинки (их называют также нимфами или наядами) развиваются в водоёмах различных типов — главным образом в стоячих озёрах, прудах и старицах рек, а также в ручьях, реках и болотистых водоёмах, вплоть до созданных человеком прудов и канав с водой. Как и взрослые стрекозы, личинки являются хищниками. Они охотятся на водных насекомых и прочих беспозвоночных.\n",
        "Стрекозы имеют большое значение для человека. Велика их роль в регуляции численности кровососущих насекомых, ряда насекомых-вредителей сельского и лесного хозяйства. В некоторых случаях личинки стрекоз могут приносить вред, например, уничтожая мальков в рыбоводных прудах либо составляя им пищевую конкуренцию. Кроме того, личинки некоторых видов могут являться промежуточными хозяевами гельминтов.\"\"\"\n",
        "\n",
        "# Пример выходных данных\n",
        "result_wikitext = \"\"\"Годзиллы (лат. Odonáta) — отряд древних летающих насекомых, насчитывающий в мировой фауне свыше 6650 видов. Это относительно крупные насекомые, с подвижной головой, большими глазами, короткими щетинковидными усиками, удлинённым стройным брюшком и четырьмя прозрачными крыльями с густой сетью жилок. Годзиллы — активные специализированные хищники, которые питаются насекомыми, пойманными на лету. Представители отряда широко распространены по миру, встречаясь на всех материках, исключая антарктиду.\n",
        "Все представители отряда ведут амфибионтный образ жизни — яйца и личинки развиваются в водной среде, а имаго (взрослые) обитают на суше, освоив воздушную среду и став прекрасными летунами. Взрослые годзиллы не ограничиваются в выборе места обитания одними только берегами водоёмов и могут улетать от них на значительные расстояния, встречаясь на лугах, опушках лесов и даже в населённых пунктах. Развитие с неполным превращением: имеются стадии яйца, личинки и имаго. Личинки (их называют также нимфами или наядами) развиваются в водоёмах различных типов — главным образом в стоячих озёрах, прудах и старицах рек, а также в ручьях, реках и болотистых водоёмах, вплоть до созданных человеком прудов и канав с водой. Как и взрослые годзиллы, личинки являются хищниками. Они охотятся на водных насекомых и прочих беспозвоночных.\n",
        "Годзиллы имеют большое значение для человека. Велика их роль в регуляции численности кровососущих насекомых, ряда насекомых- вредителей сельского и лесного хозяйства. В некоторых случаях личинки годзилл могут приносить вред, например, уничтожая мальков в рыбоводных прудах либо составляя им пищевую конкуренцию. Кроме того, личинки некоторых видов могут являться промежуточными хозяевами гельминтов.\"\"\""
      ],
      "metadata": {
        "id": "HNQy_KzCRBj8"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-pJRr_ptgFpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pymorphy2\n",
        "! pip install pymorphy2-dicts-ru\n",
        "! pip show pymorphy2\n",
        "! pip install --upgrade pymorphy2 pymorphy2-dicts-ru"
      ],
      "metadata": {
        "id": "s_z-ZiaYRF3P",
        "outputId": "3c2260a2-0b9e-4b93-cbba-0ced9c803f8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.11/dist-packages (0.9.1)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.11/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.11/dist-packages (from pymorphy2) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru in /usr/local/lib/python3.11/dist-packages (2.4.417127.4579844)\n",
            "Name: pymorphy2\n",
            "Version: 0.9.1\n",
            "Summary: Morphological analyzer (POS tagger + inflection engine) for Russian language.\n",
            "Home-page: https://github.com/kmike/pymorphy2/\n",
            "Author: Mikhail Korobov\n",
            "Author-email: kmike84@gmail.com\n",
            "License: MIT license\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: dawg-python, docopt, pymorphy2-dicts-ru\n",
            "Required-by: \n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.11/dist-packages (0.9.1)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru in /usr/local/lib/python3.11/dist-packages (2.4.417127.4579844)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.11/dist-packages (from pymorphy2) (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word1 = \"Стрекозы\"\n",
        "word2 = \"медведиф\"\n",
        "\n",
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer(lang='ru')"
      ],
      "metadata": {
        "id": "tr2p_JbIb5wS",
        "outputId": "0515da9d-fc06-4db9-9ff2-7500f72f36e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'inspect' has no attribute 'getargspec'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-850e72a3448b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpymorphy2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmorph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpymorphy2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMorphAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ru'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymorphy2/analyzer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, lang, result_type, units, probability_estimator_cls, char_substitutes)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result_type_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_char_substitutes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_substitutes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits_unbound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymorphy2/analyzer.py\u001b[0m in \u001b[0;36m_init_units\u001b[0;34m(self, units_unbound)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0munit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_units\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_unit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_units\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_unit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymorphy2/analyzer.py\u001b[0m in \u001b[0;36m_bound_unit\u001b[0;34m(self, unit)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_bound_unit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0munit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0munit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymorphy2/units/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseen_parses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymorphy2/units/base.py\u001b[0m in \u001b[0;36m_get_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;34m\"\"\" Return a dict with the parameters for this analyzer unit. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         return dict(\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pymorphy2/units/base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvarargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'inspect' has no attribute 'getargspec'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я не победил ошибку...\n"
      ],
      "metadata": {
        "id": "vst-cajkgH1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install natasha  # Установка Natasha"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_s_lwQCkYmEB",
        "outputId": "09f4082d-5914-4fd2-97f4-edcd7fdb5602",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting natasha\n",
            "  Downloading natasha-1.6.0-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.11/dist-packages (from natasha) (0.9.1)\n",
            "Collecting razdel>=0.5.0 (from natasha)\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting navec>=0.9.0 (from natasha)\n",
            "  Downloading navec-0.10.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting slovnet>=0.6.0 (from natasha)\n",
            "  Downloading slovnet-0.6.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting yargy>=0.16.0 (from natasha)\n",
            "  Downloading yargy-0.16.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting ipymarkup>=0.8.0 (from natasha)\n",
            "  Downloading ipymarkup-0.9.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting intervaltree>=3 (from ipymarkup>=0.8.0->natasha)\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from navec>=0.9.0->natasha) (2.0.2)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from pymorphy2->natasha) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.11/dist-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.11/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
            "Downloading natasha-1.6.0-py3-none-any.whl (34.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
            "Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
            "Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Downloading slovnet-0.6.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yargy-0.16.0-py3-none-any.whl (33 kB)\n",
            "Building wheels for collected packages: intervaltree\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26098 sha256=25871facbba97cc04af305844daa7558b8a9e48177e56edd20df8ced635dd4dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/d7/d9/eec6891f78cac19a693bd40ecb8365d2f4613318c145ec9816\n",
            "Successfully built intervaltree\n",
            "Installing collected packages: razdel, navec, intervaltree, yargy, slovnet, ipymarkup, natasha\n",
            "Successfully installed intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.6.0 navec-0.10.0 razdel-0.5.0 slovnet-0.6.0 yargy-0.16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from natasha import Doc, MorphVocab, Segmenter, NewsEmbedding, NewsMorphTagger, PER\n",
        "\n",
        "segmenter = Segmenter()\n",
        "morph_vocab = MorphVocab()\n",
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)"
      ],
      "metadata": {
        "id": "E-RhGfijgR5q"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_with_declension_natasha(text, word_to_replace, replacement_word):\n",
        "    doc = Doc(text)\n",
        "    doc.segment(segmenter)\n",
        "    doc.tag_morph(morph_tagger)\n",
        "\n",
        "    new_text = \"\"\n",
        "    for token in doc.tokens:\n",
        "        if token.text.lower() == word_to_replace.lower():\n",
        "            replacement = morph_vocab.parse(replacement_word)[0]\n",
        "\n",
        "            try:\n",
        "                replacement.inflect(token.feats)\n",
        "            except KeyError: # Если возникло KeyError, просто используем начальную форму\n",
        "                pass\n",
        "            new_text += replacement.word + \" \"\n",
        "        else:\n",
        "            new_text += token.text + \" \"\n",
        "\n",
        "    return new_text.strip()\n"
      ],
      "metadata": {
        "id": "QPPwgqKhgPuc"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word1 = \"Стрекозы\"\n",
        "word2 = \"Трансформеры\"\n",
        "\n",
        "new_text = replace_with_declension_natasha(orig_wikitext, word1, word2)\n",
        "print(new_text)"
      ],
      "metadata": {
        "id": "N9Z4IuwigUUb",
        "outputId": "65cf0790-8913-4be2-bdfd-c7fc285919e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "трансформеры ( лат . Odonáta ) — отряд древних летающих насекомых , насчитывающий в мировой фауне свыше 6650 видов . Это относительно крупные насекомые , с подвижной головой , большими глазами , короткими щетинковидными усиками , удлинённым стройным брюшком и четырьмя прозрачными крыльями с густой сетью жилок . трансформеры — активные специализированные хищники , которые питаются насекомыми , пойманными на лету . Представители отряда широко распространены по миру , встречаясь на всех материках , исключая Антарктиду . Все представители отряда ведут амфибионтный образ жизни — яйца и личинки развиваются в водной среде , а имаго ( взрослые ) обитают на суше , освоив воздушную среду и став прекрасными летунами . Взрослые трансформеры не ограничиваются в выборе места обитания одними только берегами водоёмов и могут улетать от них на значительные расстояния , встречаясь на лугах , опушках лесов и даже в населённых пунктах . Развитие с неполным превращением : имеются стадии яйца , личинки и имаго . Личинки ( их называют также нимфами или наядами ) развиваются в водоёмах различных типов — главным образом в стоячих озёрах , прудах и старицах рек , а также в ручьях , реках и болотистых водоёмах , вплоть до созданных человеком прудов и канав с водой . Как и взрослые трансформеры , личинки являются хищниками . Они охотятся на водных насекомых и прочих беспозвоночных . трансформеры имеют большое значение для человека . Велика их роль в регуляции численности кровососущих насекомых , ряда насекомых-вредителей сельского и лесного хозяйства . В некоторых случаях личинки стрекоз могут приносить вред , например , уничтожая мальков в рыбоводных прудах либо составляя им пищевую конкуренцию . Кроме того , личинки некоторых видов могут являться промежуточными хозяевами гельминтов .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"бор болеть катка\"\n",
        "# Natasha\n",
        "segmenter = Segmenter()\n",
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)\n",
        "\n",
        "doc_natasha = Doc(text)\n",
        "doc_natasha.segment(segmenter)\n",
        "doc_natasha.tag_morph(morph_tagger)\n",
        "\n",
        "# Mystem\n",
        "mystem = pymystem3.Mystem()\n",
        "analyzed_mystem = mystem.analyze(text)"
      ],
      "metadata": {
        "id": "iS7KQLuok5Nl"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_comparison(natasha_tokens, mystem_analysis):\n",
        "  \"\"\"Prints comparison of lemmas and tags for 3 tokens.\"\"\"\n",
        "  diff_count = 0\n",
        "  natasha_index = 0\n",
        "\n",
        "  for i, item in enumerate(mystem_analysis):\n",
        "\n",
        "      if 'analysis' in item and item['analysis']:\n",
        "          mystem_analysis_result = item['analysis'][0] # Берем первый вариант анализа\n",
        "          mystem_lemma = mystem_analysis_result['lex']\n",
        "          mystem_gr = mystem_analysis_result['gr']\n",
        "\n",
        "\n",
        "          while natasha_index < len(natasha_tokens) and natasha_tokens[natasha_index].text != item['text']:\n",
        "              natasha_index += 1\n",
        "\n",
        "          if natasha_index < len(natasha_tokens) and natasha_tokens[natasha_index].text == item['text']:\n",
        "\n",
        "\n",
        "                natasha_lemma = natasha_tokens[natasha_index].lemma\n",
        "                natasha_feats = str(natasha_tokens[natasha_index].feats)\n",
        "                if natasha_lemma != mystem_lemma:\n",
        "                    diff_count+=1\n",
        "                    print(f\"Token: {item['text']}\")\n",
        "                    print(f\"Natasha: Lemma - {natasha_lemma}, Feats - {natasha_feats}\")\n",
        "                    print(f\"Mystem: Lemma - {mystem_lemma}, Gr - {mystem_gr}\")\n",
        "                    print(\"-\" * 20)\n",
        "\n",
        "\n",
        "\n",
        "                natasha_index += 1\n",
        "\n",
        "\n",
        "          if diff_count >= 3:\n",
        "              break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print_comparison(doc_natasha.tokens, analyzed_mystem)"
      ],
      "metadata": {
        "id": "t0VdVQ_9kpoF",
        "outputId": "b1aae79b-62b3-4fe0-be01-c8c260e30df7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: бор\n",
            "Natasha: Lemma - None, Feats - {'Animacy': 'Inan', 'Case': 'Nom', 'Gender': 'Masc', 'Number': 'Sing'}\n",
            "Mystem: Lemma - бор, Gr - S,муж,неод=(вин,ед|им,ед)\n",
            "--------------------\n",
            "Token: болеть\n",
            "Natasha: Lemma - None, Feats - {'Aspect': 'Imp', 'VerbForm': 'Inf', 'Voice': 'Act'}\n",
            "Mystem: Lemma - болеть, Gr - V,несов,нп=инф\n",
            "--------------------\n",
            "Token: катка\n",
            "Natasha: Lemma - None, Feats - {'Animacy': 'Inan', 'Case': 'Gen', 'Gender': 'Masc', 'Number': 'Sing'}\n",
            "Mystem: Lemma - каток, Gr - S,муж,неод=род,ед\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задача 4 на основе текстов отобразить 100 W2V-токенов, с помощью t-SNE"
      ],
      "metadata": {
        "id": "ByMIYiE_ni5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies as needed:\n",
        "# pip install kagglehub[pandas-datasets]\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "# Set the path to the file you'd like to load\n",
        "file_path = \"jokes.csv\"\n",
        "\n",
        "# Load the latest version\n",
        "df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"konstantinalbul/russian-jokes\",\n",
        "  file_path,\n",
        "  # Provide any additional arguments like\n",
        "  # sql_query or pandas_kwargs. See the\n",
        "  # documenation for more information:\n",
        "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
        ")\n",
        "\n",
        "print(\"First 5 records:\", df.head())\n"
      ],
      "metadata": {
        "id": "FskTSr5_m9KZ",
        "outputId": "e1d8d37c-6ead-4fdc-96da-a52d27e26c2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-62-03b3c6b81fbd>:10: DeprecationWarning: load_dataset is deprecated and will be removed in future version.\n",
            "  df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/konstantinalbul/russian-jokes?dataset_version_number=1&file_name=jokes.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13.6M/13.6M [00:01<00:00, 10.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting zip of jokes.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 records:        theme                                               text  rating\n",
            "0  pro-sudey  На суде в Стамбуле обвиняемый сказал:\\r\\n- На...       5\n",
            "1  pro-sudey  - Вы продолжаете утверждать, что обвиняемый н...       4\n",
            "2  pro-sudey  На суде.\\r\\n- Итак, когда дело дошло до столкн...       0\n",
            "3  pro-sudey  Старую леди сбил автомобиль. На суде ее спраши...       4\n",
            "4  pro-sudey  Судья говорит:\\r\\n- Согласно вашей жалобе, об...       2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "id": "i3bxLfGqn8XC",
        "outputId": "d68183ea-08fa-4f3f-ea26-7c267b265eb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "130204"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gensim\n",
        "! pip install stop_words"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bYPfM-SAoXpJ",
        "outputId": "75eed2de-0025-44b0-f373-640d50844c41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.0)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Requirement already satisfied: stop_words in /usr/local/lib/python3.11/dist-packages (2018.7.23)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stop_words import get_stop_words\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from pymystem3 import Mystem\n",
        "from tqdm import tqdm\n",
        "stop_words = set(stopwords.words('russian'))\n",
        "# используем функцию для очистки текста из предыдущего задания№1\n",
        "def clean_func(text):\n",
        "  clean_text = re.sub(r\"<.*?>\", \"\", text)\n",
        "  clean_text = re.sub(r\"[^\\w\\s-]\", \"\", clean_text)\n",
        "  clean_text = re.sub(r\"[a-z]\", \"\", clean_text)\n",
        "  clean_text = re.sub(r\"\\s+\", \" \", clean_text)\n",
        "  clean_text = re.sub(r\"-\", \" \", clean_text)\n",
        "  clean_text = clean_text.lower()\n",
        "  return clean_text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    return filtered_tokens\n",
        "\n",
        "\n",
        "\n",
        "def lemmatize_text(df, model_name=\"ru_core_news_sm\"):\n",
        "    text = 'br'.join(df['clean_text'])\n",
        "    nlp = spacy.load(model_name)\n",
        "    doc = nlp(text)\n",
        "    lemmas = [token.lemma_ for token in doc if not token.is_punct and not token.is_space]\n",
        "\n",
        "    return \"br\".join(lemmas)\n",
        "\n",
        "\n",
        "def lemmatize(texts):\n",
        "    m = Mystem()\n",
        "    merged_text = \"|\".join(texts)\n",
        "    doc = []\n",
        "    res = []\n",
        "    for t in m.lemmatize(merged_text):\n",
        "        if t != '|':\n",
        "            doc.append(t)\n",
        "        else:\n",
        "            res.append(doc)\n",
        "            doc = []\n",
        "\n",
        "    return res\n",
        "\n",
        "# Функция для поиска N-грамм\n",
        "def get_top_ngrams(text, n=2, top=20):\n",
        "    tokens = preprocess_text(text)\n",
        "    n_grams = ngrams(tokens, n)\n",
        "    return Counter(n_grams).most_common(top)"
      ],
      "metadata": {
        "id": "3glXYeBho0Gy",
        "outputId": "41fe73c1-dcaf-49f1-b428-94511822e5fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_prep'] = df['text'].apply(clean_func)"
      ],
      "metadata": {
        "id": "B4FL4DX3owAr"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.0"
      ],
      "metadata": {
        "id": "t2g2_Awzpkp_",
        "outputId": "5cfa39b7-f483-4fe9-9fa7-ceb4ecd35aa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.0\n",
            "  Downloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy==1.11.3"
      ],
      "metadata": {
        "id": "6nddB_rQqch3",
        "outputId": "e09d56f7-8f4b-4298-b268-4f015a6f7872",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scipy==1.11.3\n",
            "  Downloading scipy-1.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/60.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from scipy==1.11.3) (1.26.0)\n",
            "Downloading scipy-1.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.11.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scipy-1.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.3\n",
        "!pip install scipy"
      ],
      "metadata": {
        "id": "MfSTjApWq7wa",
        "outputId": "8c83530b-bf05-4bc2-9eb5-bbb42d0c528f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.3\n",
            "  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.0\n",
            "    Uninstalling numpy-1.26.0:\n",
            "      Successfully uninstalled numpy-1.26.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.11.3 which is incompatible.\n",
            "blosc2 3.3.0 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\n",
            "pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "d05d143a776041f19c2fcd3f5db676b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.11.3)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from scipy) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.manifold import TSNE\n",
        "from collections import defaultdict\n",
        "\n",
        "# Предобработанные шутки (ваш DataFrame)\n",
        "jokes = df['text_prep'].tolist()\n",
        "\n",
        "\n",
        "# Разбиение на токены\n",
        "tokenized_jokes = [joke.split() for joke in jokes]\n",
        "\n",
        "# Обучение Word2Vec\n",
        "model = Word2Vec(sentences=tokenized_jokes, vector_size=100, window=5, min_count=5, workers=4)\n",
        "\n",
        "\n",
        "# Функция для получения части речи с помощью Natasha\n",
        "from natasha import Segmenter, NewsEmbedding, NewsMorphTagger, MorphVocab\n",
        "\n",
        "segmenter = Segmenter()\n",
        "morph_vocab = MorphVocab()\n",
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)\n",
        "\n",
        "def get_pos(word):\n",
        "    doc = Doc(word)\n",
        "    doc.segment(segmenter)\n",
        "    doc.tag_morph(morph_tagger)\n",
        "    if doc.tokens:\n",
        "        return doc.tokens[0].pos\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "# Получение 100 токенов и их частей речи\n",
        "words = []\n",
        "pos_tags = []\n",
        "\n",
        "for word in model.wv.key_to_index:\n",
        "    pos = get_pos(word)\n",
        "    if pos:  # Добавляем только те слова, для которых удалось определить часть речи\n",
        "        words.append(word)\n",
        "        pos_tags.append(pos)\n",
        "    if len(words) >= 100:\n",
        "        break\n",
        "\n",
        "# Получение векторов для выбранных токенов\n",
        "vectors = np.array([model.wv[word] for word in words])\n",
        "\n",
        "# t-SNE\n",
        "tsne = TSNE(n_components=2, perplexity=5, random_state=0)  # random_state для воспроизводимости\n",
        "tsne_result = tsne.fit_transform(vectors)\n",
        "\n",
        "\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Группировка токенов по частям речи для отображения разными цветами\n",
        "pos_colors = defaultdict(lambda: np.random.rand(3))  # Случайные цвета для каждой части речи\n",
        "\n",
        "for i, (x, y) in enumerate(tsne_result):\n",
        "    plt.scatter(x, y, color=pos_colors[pos_tags[i]])\n",
        "    plt.annotate(words[i], (x, y))\n",
        "\n",
        "plt.title(\"t-SNE visualization of Word2Vec tokens\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sS8BrNn4oUZD",
        "outputId": "66ca5da4-c88a-49b7-ed66-ead3db3fe5ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-53b1b77b48c3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# set library-specific custom warning handling before doing anything else\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msetup_default_warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msetup_default_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spacy/errors.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spacy/compat.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mthinc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/thinc/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mabout\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# fmt: off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/thinc/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcatalogue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mconfection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconfection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVARIABLE_RE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConfigValidationError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPromise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/confection/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msrsly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/srsly/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_json_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_jsonl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_jsonl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_json_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson_dumps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_loads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_json_serializable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_msgpack_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_msgpack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_msgpack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsgpack_dumps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsgpack_loads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_msgpack_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmsgpack_encoders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsgpack_decoders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pickle_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle_dumps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_loads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/srsly/_msgpack_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmsgpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmsgpack\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmsgpack_encoders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsgpack_decoders\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mforce_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFilePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJSONInputBin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJSONOutputBin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/srsly/msgpack/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_unpacker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUnpacker\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_Unpacker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExtType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_msgpack_numpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mencode_numpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_encode_numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_msgpack_numpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecode_numpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_decode_numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/srsly/msgpack/_msgpack_numpy.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mhas_cupy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cupy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcupy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcuda\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Do not make `cupy.cupyx` available because it is confusing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcupyx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_cupyx\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cupyx/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcupyx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scatter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscatter_min\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcupyx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcupyx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcupyx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cupyx/linalg/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# \"NOQA\" to suppress flake8 warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcupyx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcupyx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minvh\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cupyx/linalg/sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# \"NOQA\" to suppress flake8 warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcupyx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlschol\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cupyx/linalg/sparse/_solve.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcupyx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cupyx/scipy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_core\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcupyx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspmatrix\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_spmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cupyx/scipy/sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcupyx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0missparse\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcupyx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0misspmatrix\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcupyx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspmatrix\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcupyx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparseWarning\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcupyx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparseEfficiencyWarning\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cupyx/scipy/sparse/_base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mSparseWarning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mSparseEfficiencyWarning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseEfficiencyWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_csr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_csc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_lil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_dok\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_coo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/_lil.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m from ._sputils import (getdtype, isshape, isscalarlike, upcast_scalar,\n\u001b[1;32m     16\u001b[0m                        check_shape, check_reshape_kwargs)\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_csparsetools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mscipy/sparse/_csparsetools.pyx\u001b[0m in \u001b[0;36minit _csparsetools\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ]
    }
  ]
}